---
title: 'Assignment #2'
author: "Tshering Wangchuk"
date: "9/14/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
library(tidyverse)         # for graphing and data cleaning
library(tidymodels)        # for modeling
library(naniar)            # for analyzing missing values
library(vip)               # for variable importance plots
library(ggthemes)
theme_set(theme_minimal()) # Lisa's favorite theme
```

```{r data}
hotels <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv')
```


When you finish the assignment, remove the `#` from the options chunk at the top, so that messages and warnings aren't printed. If you are getting errors in your code, add `error = TRUE` so that the file knits. I would recommend not removing the `#` until you are completely finished.

## Put it on GitHub!        

From now on, GitHub should be part of your routine when doing assignments. I recommend making it part of your process anytime you are working in R, but I'll make you show it's part of your process for assignments.

**Task**: When you are finished with the assignment, post a link below to the GitHub repo for the assignment. 


## Machine Learning review and intro to `tidymodels`

Read through and follow along with the [Machine Learning review with an intro to the `tidymodels` package](https://advanced-ds-in-r.netlify.app/posts/2021-03-16-ml-review/) posted on the Course Materials page. 

**Tasks**:

1. Read about the hotel booking data, `hotels`, on the [Tidy Tuesday page](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md) it came from. There is also a link to an article from the original authors. The outcome we will be predicting is called `is_canceled`. 

  - Without doing any analysis, what are some variables you think might be predictive and why?
  
<br> Some variables that are predictive are: i) ADR- the average daily rate reflects the prices and will help us predict the outcome of other variables ii) hotel - the type of hotel will determine many variables such as daily rate, customer types etc. 
  _ What are some problems that might exist with the data? You might think about how it was collected and who did the collecting.  
  
<br> On a higher level, the dataset we are using to identify patterns and relationships in hotels has only been collected from one resort hotel and one city hotel, which could impact the replicability of our models on other hotels.  

  - If we construct a model, what type of conclusions will be able to draw from it?  
  
<br> The model will allow us to understand how variables in the dataframe such interact with eachother and we will be able to observe patters and relationships that will inform our understanding of the hotel industry. 
  
2. Create some exploratory plots or table summaries of the variables in the dataset. Be sure to also examine missing values or other interesting values. You may want to adjust the `fig.width` and `fig.height` in the code chunk options. 

<br> We can observe in the graph below that City Hotel's are approximately twice as popular as Resort Hotels, in the dataframe. 

```{r, fig.width= 7, fig.height=5}
hotels %>% ggplot(aes(x = hotel, fill = hotel)) + geom_bar() + theme_clean() + theme(legend.position = "none") 
```

<br> The graph below allows us to understand the different composition of customers, respective to the hotel types. 

```{r}
hotels %>% ggplot(aes(x = hotel, fill = customer_type)) + geom_bar() + theme_clean()
```
<br> The visualization below informs us that in the three years of data available, months like August and July have been the most profitable for the hotel industry. 

```{r, fig.widt= 50}
hotels %>% mutate(arrival_date_day_of_month = factor(arrival_date_month, levels = month.abb)) %>%
  ggplot(aes(y = adr, x = arrival_date_month, fill = arrival_date_month)) + geom_col() + theme_clean() + 
  theme(axis.text.x=element_blank())
```
<br> The table below allows us to understand the distribution of cancellations with respect to the different months. 

```{r}
hotels %>% count(is_canceled, arrival_date_month)
```

3. First, we will do a couple things to get the data ready. 

* I did the following for you: made outcome a factor (needs to be that way for logistic regression), made all character variables factors, removed the year variable and some reservation status variables, and removed cases with missing values (not NULLs but true missing values).

* You need to split the data into a training and test set, stratifying on the outcome variable, `is_canceled`. Since we have a lot of data, split the data 50/50 between training and test. I have already `set.seed()` for you. Be sure to use `hotels_mod` in the splitting.

```{r}
hotels_mod <- hotels %>% 
  mutate(is_canceled = as.factor(is_canceled)) %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  select(-arrival_date_year,
         -reservation_status,
         -reservation_status_date) %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)

set.seed(494)
```

<br> Splitting the dataset for training and testing in the chunk below. 

```{r}
set.seed(494)

hotels_split <- initial_split(hotels_mod, 
                             prop = .5)

hotels_training<-training(hotels_split)
hotels_testing<- testing(hotels_split)
```

4. In this next step, we are going to do the pre-processing. Usually, I won't tell you exactly what to do here, but for your first exercise, I'll tell you the steps. 

* Set up the recipe with `is_canceled` as the outcome and all other variables as predictors (HINT: `~.`).  
* Use a `step_XXX()` function or functions (I think there are other ways to do this, but I found `step_mutate_at()` easiest) to create some indicator variables for the following variables: `children`, `babies`, and `previous_cancellations`. So, the new variable should be a 1 if the original is more than 0 and 0 otherwise. Make sure you do this in a way that accounts for values that may be larger than any we see in the dataset.  
* For the `agent` and `company` variables, make new indicator variables that are 1 if they have a value of `NULL` and 0 otherwise. I also used `step_mutate_at()` for this, but there's more ways you could do it.
* Use `fct_lump_n()` inside `step_mutate()` to lump together countries that aren't in the top 5 most occurring. 
* If you used new names for some of the new variables you created, then remove any variables that are no longer needed. 
* Use `step_normalize()` to center and scale all the non-categorical predictor variables. (Do this BEFORE creating dummy variables. When I tried to do it after, I ran into an error - I'm still [investigating](https://community.rstudio.com/t/tidymodels-see-notes-error-but-only-with-step-xxx-functions-in-a-certain-order/115006) why.)
* Create dummy variables for all factors/categorical predictor variables (make sure you have `-all_outcomes()` in this part!!).  
* Use the `prep()` and `juice()` functions to apply the steps to the training data just to check that everything went as planned.

<br> Setting the recipe

```{r}
hotel_recipe <-recipe(is_canceled~., data = hotels_training) 
```

<br> Pre-processing 

```{r}
hotel_recipe <- recipe(is_canceled~., data = hotels_training) %>%                 
                  step_mutate_at(children, babies, previous_cancellations, fn= ~ as.numeric(. > 0)) %>% 
                  step_mutate_at(agent, company, fn= ~ as.numeric(. == "NULL") %>%
                  step_mutate(country = fct_lump_n(f = (country),5)) %>%
                  step_normalize(all_predictors()),
                                 -all_nominal()) %>%
                  step_dummy(all_nominal(), -all_outcomes())
```

            
<br> Applying steps to training data in the chunk below

```{r}
hotel_recipe %>% 
  prep() %>% 
  juice()
```


5. In this step we will set up a LASSO model and workflow.

* In general, why would we want to use LASSO instead of regular logistic regression? (HINT: think about what happens to the coefficients).  
* Define the model type, set the engine, set the `penalty` argument to `tune()` as a placeholder, and set the mode.  
* Create a workflow with the recipe and model.  

<br> Setting engine mode and creating workflow. 

```{r}
hotels_mod <- logistic_reg(mixture = 1) %>%
  set_args(penalty =tune()) %>%
  set_engine("glmnet") %>% 
  set_mode("classification")
```


```{r}
hotels_wf <- workflow() %>% 
  add_recipe(hotel_recipe) %>% 
  add_model(hotels_mod)
```

6. In this step, we'll tune the model and fit the model using the best tuning parameter to the entire training dataset.

* Create a 5-fold cross-validation sample. We'll use this later. I have set the seed for you.  
* Use the `grid_regular()` function to create a grid of 10 potential penalty parameters (we're keeping this sort of small because the dataset is pretty large). Use that with the 5-fold cv data to tune the model.  
* Use the `tune_grid()` function to fit the models with different tuning parameters to the different cross-validation sets.  
* Use the `collect_metrics()` function to collect all the metrics from the previous step and create a plot with the accuracy on the y-axis and the penalty term on the x-axis. Put the x-axis on the log scale.  
* Use the `select_best()` function to find the best tuning parameter, fit the model using that tuning parameter to the entire training set (HINT: `finalize_workflow()` and `fit()`), and display the model results using `pull_workflow_fit()` and `tidy()`. Are there some variables with coefficients of 0?

```{r}
set.seed(494) # for reproducibility
hotel_cv <- vfold_cv(hotels_training, v = 5)
pen_grid <- grid_regular(penalty(),levels = 10)
pen_grid
```

```{r}
hotels_lasso_tune <-
  hotels_wf %>% 
  tune_grid(hotel_recipe, resamples = hotel_cv, grid = pen_grid) 
hotels_lasso_tune
```


```{r}
collect_metrics(hotels_lasso_tune)
```

```{r}
collect_metrics(hotels_lasso_tune) %>% 
  ggplot(aes(x = log10(penalty), y= mean, color = .metric))+
  geom_point()
```

<br> Finding the best tune parameter

```{r}
hotels_best<- select_best(hotels_lasso_tune, metric = 'roc_auc')
hotels_best
```

```{r}
hotels_final_wf <- hotels_wf %>% 
  finalize_workflow(hotels_best)

hotels_final_wf
```

<br> Fitting the model below. 

```{r}
hotels_fit <- hotels_final_wf %>%
  fit(data = hotels_training)
```

<br> Displaying the model below. 

```{r}
hotels_fit %>% pull_workflow_fit() %>% tidy()
```

<br> We can see above that there are some variables such as distribution_channel_undefined, arrival date month and customer type have a coefficient of 0. 

7. Now that we have a model, let's evaluate it a bit more. All we have looked at so far is the cross-validated accuracy from the previous step. 

* Create a variable importance graph. Which variables show up as the most important? Are you surprised? 

```{r}
library(vip)
hotels_fit %>% 
  pull_workflow_fit() %>% 
  vip()
```
<br> I am not surprised to see reserved room type as an important variable since the type of room will affect the cancellation however I am surprised to see company. 

* Use the `last_fit()` function to fit the final model and then apply it to the testing data. Report the metrics from the testing data using the `collet_metrics()` function. How do they compare to the cross-validated metrics?

```{r}
hotels_final_test <- hotels_final_wf %>% 
  last_fit(hotels_split) 

hotels_final_test %>% collect_metrics()
```
<br> The cross validated metrics were roc_auc of 0.91 and accuracy of 0.83 and compared to that the testing metrics are approximately same with the accuracy value very slightly better than the CV one.

* Use the `collect_predictions()` function to find the predicted probabilities and classes for the test data. Save this to a new dataset called `preds`. Then, use the `conf_mat()` function from `dials` (part of `tidymodels`) to create a confusion matrix showing the predicted classes vs. the true classes. Compute the true positive rate (sensitivity), true negative rate (specificity), and accuracy. See this [Wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix) reference if you (like me) tend to forget these definitions. Also keep in mind that a "positive" in this case is a cancellation (those are the 1's).

```{r}
preds<-collect_predictions(hotels_final_test) 

hotels_mat<-preds%>%
  conf_mat(is_canceled, .pred_class)

hotels_mat
```

<br> Calculating the sensitivity:

```{r}
34085 / (34085 + 3516)
```

<br> Calculating the specficity:

```{r}
15602 / (15062 + 6490)
```

<br> Calculating the accuracy

```{r}
(34085 + 15062) / (34085 + 15062 + 6490 + 3516)
```

* Use the `preds` dataset you just created to create a density plot of the predicted probabilities of canceling (the variable is called `.pred_1`), filling by `is_canceled`. Use an `alpha = .5` and `color = NA` in the `geom_density()`. Answer these questions: 

```{r}
preds%>%
  ggplot(aes(x = .pred_1, fill = is_canceled))+
  geom_density(alpha = 0.5, color = NA)
```

a. What would this graph look like for a model with an accuracy that was close to 1?  

<br> If accuracy was close to 1, then we would have peaks at only 0 and 1.

b. Our predictions are classified as canceled if their predicted probability of canceling is greater than .5. If we wanted to have a high true positive rate, should we make the cutoff for predicted as canceled higher or lower than .5?

<br> Cutoff should be lower than 0.5.

c. What happens to the true negative rate if we try to get a higher true positive rate?

<br> The true negative rate will be lower if the true positive rate is higher.

8. Let's say that this model is going to be applied to bookings 14 days in advance of their arrival at each hotel, and someone who works for the hotel will make a phone call to the person who made the booking. During this phone call, they will try to assure that the person will be keeping their reservation or that they will be canceling in which case they can do that now and still have time to fill the room. How should the hotel go about deciding who to call? How could they measure whether it was worth the effort to do the calling? Can you think of another way they might use the model? 

<br> The hotels should reference the variable importance graph. They should call people associated with the respective variables. Alternative methods of using the model could be for identifying certain customers or factors that are likely to cancel. For example, company_X370 is an important variable hence the hotel might have to reevaluate the business relationship they have with them, allowing the hotel to make strategic decisions.  

9. How might you go about questioning and evaluating the model in terms of fairness? Are there any questions you would like to ask of the people who collected the data? 

<br> With regards to the data, the tidy tuesday site give us indepth information and description of the data being used, the purposes and how it is valuable. They responsibily removed any form of identification / personal information from the datatset to respect the privacy of both the hotels and their customers. 



## Bias and Fairness

Read [Chapter 1: The Power Chapter](https://data-feminism.mitpress.mit.edu/pub/vi8obxh7/release/4) of Data Feminism by Catherine D'Ignazio and Lauren Klein. Write a 4-6 sentence paragraph reflecting on this chapter. As you reflect, you might consider responding to these specific questions. We will also have a discussion about these questions in class on Thursday.

<br> The article provides a very precise and informative look into how bias and systems of oppression can easily and unknowingly transfer into advanced technology such as AI and algorithms. The author spends extensive time highlighting the disparities between men and women who work in the technology industry whereby men are disproportionately more by a large gap and how those in positions of privilege influence the way in which these technologies are created, and then advanced. The reading allows us to think about the impacts of technology as it becomes more automated and its ability to affect the fabric of society. 


